

# opentack **Rocky** 版 安装使用

## 基础环境

虚拟机 Ubuntu 18.04 desktop 最好是server

### 目前三个节点硬件

| nodeName   | cpu  | 内存 | 硬盘 |
| ---------- | ---- | ---- | ---- |
| controller | 4    | 8G   | 50G  |
| compute    | 8    | 8G   | 50G  |
| network    | 4    | 4G   | 50G  |

### 目前三个节点网络

| nodeName   | 网络IP           | 管理IP          | 数据IP          |
| ---------- | ---------------- | --------------- | --------------- |
| controller | 192.168.30.90/24 | 192.168.1.10/24 | 192.168.2.10/24 |
| compute    | 192.168.30.91/24 | 192.168.1.20/24 | 192.168.2.20/24 |
| network    | 192.168.30.93/24 | 192.168.1.30/24 | 192.168.2.30/24 |

### 虚拟机准备：

1. 安装ssh

```
# 更新
sudo apt-get update
# 安装
sudo apt-get intall openssh-server
```

2. 启动服务

```
sudo service ssh start
```

3. 开机启动

~~~
sudo systemctl enable ssh
~~~

4. 修改阿里源

```
# 备份
sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak
# 修改文件
sudo vim /etc/apt/sources.list
# 报错安装 vim
sudo apt-get install vim
# 查看系统版本
lsb_release -c
# 修改 sources.list：
# 阿里云 https://developer.aliyun.com/mirror/ubuntu?spm=a2c6h.13651102.0.0.3e221b11AiCbIK

deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse

# 更新软件列表
sudo apt-get update
# 更新软件包
sudo apt-get upgrade
```

### 网络配置：

https://help.ubuntu.com/lts/serverguide/network-configuration.html

~~~
vim /etc/netplan/01-network-manager-all.yaml
~~~



~~~
# Let NetworkManager manage all devices on this system

# controller
network:
  version: 2
  ethernets:
          ens160:
                 addresses: [192.168.30.90/24]
                 gateway4: 192.168.30.254
                 nameservers:
                         addresses: [202.114.64.2]
          ens192:
                  addresses: [192.168.1.10/24]
                  gateway4: 192.168.1.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]
          ens224:
                  addresses: [192.168.2.10/24]
                  gateway4: 192.168.2.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]

# compute
network:
  version: 2
  ethernets:
          ens160:
                 addresses: [192.168.30.91/24]
                 gateway4: 192.168.30.254
                 nameservers:
                         addresses: [202.114.64.2]
          ens192:
                  addresses: [192.168.1.20/24]
                  gateway4: 192.168.1.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]
          ens224:
                  addresses: [192.168.2.20/24]
                  gateway4: 192.168.2.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]
# network
network:
  version: 2
  ethernets:
          ens160:
                 addresses: [192.168.30.93/24]
                 gateway4: 192.168.30.254
                 nameservers:
                         addresses: [202.114.64.2]
          ens192:
                  addresses: [192.168.1.30/24]
                  gateway4: 192.168.1.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]
          ens224:
                  addresses: [192.168.2.30/24]
                  gateway4: 192.168.2.0
                  nameservers:
                          addresses: [8.8.8.8, 8.8.4.4]

~~~

~~~
netplan apply
reboot
~~~



### hosts文件配置

~~~
vim /etc/hosts

192.168.1.10    controller
192.168.1.20    compute
192.168.1.30    network
~~~

------ 建立快照 ------  ssh vim 网络配置 hosts配置

## openstack **Rocky**  环境搭建

https://docs.openstack.org/install-guide/

### 密码规则

~~~
openssl rand -hex 10
~~~

| Password name                              | Description                                        |
| :----------------------------------------- | :------------------------------------------------- |
| Database password (no variable used)  root | Root password for the database                     |
| `ADMIN_PASS`                               | Password of user `admin`                           |
| `CINDER_DBPASS`                            | Database password for the Block Storage service    |
| `CINDER_PASS`                              | Password of Block Storage service user `cinder`    |
| `DASH_DBPASS`                              | Database password for the Dashboard                |
| `DEMO_PASS`                                | Password of user `demo`                            |
| `GLANCE_DBPASS`                            | Database password for Image service                |
| `GLANCE_PASS`                              | Password of Image service user `glance`            |
| `KEYSTONE_DBPASS`                          | Database password of Identity service              |
| `METADATA_SECRET`                          | Secret for the metadata proxy                      |
| `NEUTRON_DBPASS`                           | Database password for the Networking service       |
| `NEUTRON_PASS`                             | Password of Networking service user `neutron`      |
| `NOVA_DBPASS`                              | Database password for Compute service              |
| `NOVA_PASS`                                | Password of Compute service user `nova`            |
| `PLACEMENT_PASS`                           | Password of the Placement service user `placement` |
| `RABBIT_PASS`                              | Password of RabbitMQ user `openstack`              |

### NTP 配置

#### controller node 配置

~~~
apt install chrony
~~~

edit the `/etc/chrony/chrony.conf` file:

```
# server NTP_SERVER iburst
# NTP_SERVER = ntp1.aliyun.com

server ntp1.aliyun.com iburst
server time4.aliyun.com iburst

```

To enable other nodes to connect to the chrony daemon on the controller node, add this key to the same `chrony.conf` file mentioned above:

```
allow 192.168.1.0/24
```

~~~
service chrony restart
systemctl enable chrony
~~~

#### other node 配置

```
apt install chrony
```

edit the `/etc/chrony/chrony.conf` file:

```
server controller iburst
```

```
service chrony restart
systemctl enable chrony
```

#### 验证

##### controller node

```
chronyc sources

210 Number of sources = 1
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* 120.25.115.20                 2   6   337    25    +79us[ +102us] +/-   12ms
```

##### other node

```
chronyc sources

210 Number of sources = 1
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* controller                    3   6    37    62   -617ns[+8360ns] +/-   12ms
```

### OpenStack packages

https://docs.openstack.org/install-guide/environment-packages-ubuntu.html

#### 仓库配置

> 三个节点都要进行

**OpenStack Rocky for Ubuntu 18.04 LTS:**

```
# add-apt-repository cloud-archive:rocky
```

#### 完成安装

1. Upgrade packages on all nodes:

   ```
   # apt update && apt dist-upgrade
   ```

   

   > Note
   >
   > If the upgrade process includes a new kernel, reboot your host to activate it.

   

2. Install the OpenStack client:

   **OpenStack Stein for Ubuntu 18.04 LTS:**

   ```
   # apt install python3-openstackclient
   ```

重启三节点

~~~
reboot
~~~

### SQL Database

> 只需在 controller node 进行

#### 安装配置

1. Install the packages:

   ```
   # apt install mariadb-server python-pymysql
   ```

2. Create and edit the `/etc/mysql/mariadb.conf.d/99-openstack.cnf` file and complete the following actions:

- Create a `[mysqld]` section, and set the `bind-address` key to the management IP address of the controller node to enable access by other nodes via the management network. Set additional keys to enable useful options and the UTF-8 character set:

  ```
  [mysqld]
  bind-address = 192.168.1.10
  
  default-storage-engine = innodb
  innodb_file_per_table = on
  max_connections = 4096
  collation-server = utf8_general_ci
  character-set-server = utf8
  ```

#### 完成安装

```
service mysql restart
```

```
mysql_secure_installation
```

> 密码 root

### [RabbitMQ](https://www.rabbitmq.com/) 消息队列

> 在controller node 上进行

#### 安装配置

1. Install the package:

   ```
   # apt install rabbitmq-server
   ```

2. Add the `openstack` user:

   ```
   # rabbitmqctl add_user openstack RABBIT_PASS
   
   Creating user "openstack" ...
   ```

   Replace `RABBIT_PASS` with a suitable password.

3. Permit configuration, write, and read access for the `openstack` user:

   ```
   # rabbitmqctl set_permissions openstack ".*" ".*" ".*"
   
   Setting permissions for user "openstack" in vhost "/" ...
   ```

~~~
service rabbitmq-server restart
systemctl enable rabbitmq-server
~~~



### Memcached 缓存服务

> 在controller node进行

1. Install the packages:

   ```
   # apt install memcached python-memcache
   ```

2. Edit the `/etc/memcached.conf` file and configure the service to use the management IP address of the controller node. This is to enable access by other nodes via the management network:

```
-l 192.168.1.10
```

#### 完成安装

```
service memcached restart
```

## 核心组件安装

### Keystone

> https://docs.openstack.org/keystone/rocky/install/index-ubuntu.html
>
> 在controller node 上进行

#### 安装配置

##### 准备

Before you install and configure the Identity service, you must create a database.

1. Use the database access client to connect to the database server as the `root` user:

   ```
   # mysql
   ```

2. Create the `keystone` database:

```
MariaDB [(none)]> CREATE DATABASE keystone;
```

3. Grant proper access to the `keystone` database:

```
MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \
IDENTIFIED BY 'KEYSTONE_DBPASS';
MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \
IDENTIFIED BY 'KEYSTONE_DBPASS';

MariaDB [(none)]> flush privileges;
```

Replace `KEYSTONE_DBPASS` with a suitable password.

4. Exit the database access client.

##### 安装

1. Run the following command to install the packages:

   ```
   # apt install keystone  apache2 libapache2-mod-wsgi
   ```

2. Edit the `/etc/keystone/keystone.conf` file and complete the following actions:

- 取消注释并修改ip   

  610行

  ~~~
  memcache_servers = 192.168.1.10:11211
  ~~~

- In the `[database]` section, configure database access:

  ```
  [database]
  # ...
  connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone
  ```

  Replace `KEYSTONE_DBPASS` with the password you chose for the database.

  

  > Note
  >
  > Comment out or remove any other `connection` options in the `[database]` section.

  

- In the `[token]` section, configure the Fernet token provider:

  ```
  [token]
  # ...
  provider = fernet
  ```

3. Populate the Identity service database:

```
# su -s /bin/sh -c "keystone-manage db_sync" keystone
```

4. Initialize Fernet key repositories:

```
# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
```

5. Bootstrap the Identity service:

> Note
>
> Before the Queens release, keystone needed to be run on two separate ports to accommodate the Identity v2 API which ran a separate admin-only service commonly on port 35357. With the removal of the v2 API, keystone can be run on the same port for all interfaces.

设置临时变量

~~~
export controller=192.168.1.10
~~~

```
# keystone-manage bootstrap --bootstrap-password ADMIN_PASS \
  --bootstrap-admin-url http://$controller:5000/v3/ \
  --bootstrap-internal-url http://$controller:5000/v3/ \
  --bootstrap-public-url http://$controller:5000/v3/ \
  --bootstrap-region-id RegionOne
```

Replace `ADMIN_PASS` with a suitable password for an administrative user.



##### 配置Apache HTTP server

Edit the `/etc/apache2/apache2.conf` file and configure the `ServerName` option to reference the controller node:

```
ServerName controller
```

##### 完成安装

1. Restart the Apache service:

   ```
   # service apache2 restart
   systemctl enable apache2
   ```

2. Configure the administrative account

```
export OS_USERNAME=admin
export OS_PASSWORD=ADMIN_PASS
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
```

Replace `ADMIN_PASS` with the password used in the `keystone-manage bootstrap` command in [keystone-install-configure-ubuntu](https://docs.openstack.org/keystone/queens/install/keystone-install-ubuntu.html#keystone-install-configure-ubuntu).

或 ↓ （测试通过的是第一种）

~~~
# 添加环境变量文件
root@controller:~# vim ~/keystonerc
 
export OS_PROJECT_DOMAIN_NAME=default
export OS_USER_DOMAIN_NAME=default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=root
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
export PS1='\u@\h \W(keystone)\$ '
 
# 在以后使用中经常需要先引入这里设置的临时环境变量，为了避免麻烦，这里直接设置bash自动加载环境变量文件
root@controller:~# chmod 600 ~/keystonerc
root@controller:~# source ~/keystonerc
root@controller:~(keystone)# echo "source ~/keystonerc " >> ~/.bash_profile
~~~

##### 创建domain, projects, users, and roles

1. Although the “default” domain already exists from the keystone-manage bootstrap step in this guide, a formal way to create a new domain would be:

   ```
   $ openstack domain create --description "An Example Domain" example
   
   +-------------+----------------------------------+
   | Field       | Value                            |
   +-------------+----------------------------------+
   | description | An Example Domain                |
   | enabled     | True                             |
   | id          | 2f4f80574fd84fe6ba9067228ae0a50c |
   | name        | example                          |
   | tags        | []                               |
   +-------------+----------------------------------+
   ```

2. This guide uses a service project that contains a unique user for each service that you add to your environment. Create the `service` project:

   ```
   $ openstack project create --domain default --description "Service Project" service
   
   +-------------+----------------------------------+
   | Field       | Value                            |
   +-------------+----------------------------------+
   | description | Service Project                  |
   | domain_id   | default                          |
   | enabled     | True                             |
   | id          | cc60f7c2d98347e0832bfa02b21ae94f |
   | is_domain   | False                            |
   | name        | service                          |
   | parent_id   | default                          |
   | tags        | []                               |
   +-------------+----------------------------------+
   ```

3. Regular (non-admin) tasks should use an unprivileged project and user. As an example, this guide creates the `myproject` project and `myuser` user.

   - Create the `myproject` project:

     ```
     $ openstack project create --domain default --description "Demo Project" myproject
     
     +-------------+----------------------------------+
     | Field       | Value                            |
     +-------------+----------------------------------+
     | description | Demo Project                     |
     | domain_id   | default                          |
     | enabled     | True                             |
     | id          | 231ad6e7ebba47d6a1e57e1cc07ae446 |
     | is_domain   | False                            |
     | name        | myproject                        |
     | parent_id   | default                          |
     | tags        | []                               |
     +-------------+----------------------------------+
     ```

     

     > Note
     >
     > Do not repeat this step when creating additional users for this project.

     

   - Create the `myuser` user:

     ```
     $ openstack user create --domain default --password-prompt myuser
     
     User Password: DEMO_PASS
     Repeat User Password: DEMO_PASS
     +---------------------+----------------------------------+
     | Field               | Value                            |
     +---------------------+----------------------------------+
     | domain_id           | default                          |
     | enabled             | True                             |
     | id                  | aeda23aa78f44e859900e22c24817832 |
     | name                | myuser                           |
     | options             | {}                               |
     | password_expires_at | None                             |
     +---------------------+----------------------------------+
     ```

   - Create the `myrole` role:

     ```
     $ openstack role create myrole
     
     +-----------+----------------------------------+
     | Field     | Value                            |
     +-----------+----------------------------------+
     | domain_id | None                             |
     | id        | 997ce8d05fc143ac97d83fdfb5998552 |
     | name      | myrole                           |
     +-----------+----------------------------------+
     ```

   - Add the `myrole` role to the `myproject` project and `myuser` user:

     ```
     $ openstack role add --project myproject --user myuser myrole
     ```

     

     > Note
     >
     > This command provides no output.

------

对controller node 建立快照

> keystone

------

##### 验证

1. Unset the temporary `OS_AUTH_URL` and `OS_PASSWORD` environment variable:

```
$ unset OS_AUTH_URL OS_PASSWORD
```

2. As the `admin` user, request an authentication token:

```
$ openstack --os-auth-url http://controller:5000/v3 \
  --os-project-domain-name Default --os-user-domain-name Default \
  --os-project-name admin --os-username admin token issue

Password: ADMIN_PASS
+------------+-----------------------------------------------------------------+
| Field      | Value                                                           |
+------------+-----------------------------------------------------------------+
| expires    | 2016-02-12T20:14:07.056119Z                                     |
| id         | gAAAAABWvi7_B8kKQD9wdXac8MoZiQldmjEO643d-e_j-XXq9AmIegIbA7UHGPv |
|            | atnN21qtOMjCFWX7BReJEQnVOAj3nclRQgAYRsfSU_MrsuWb4EDtnjU7HEpoBb4 |
|            | o6ozsA_NmFWEpLeKy0uNn_WeKbAhYygrsmQGA49dclHVnz-OMVLiyM9ws       |
| project_id | 343d245e850143a096806dfaefa9afdc                                |
| user_id    | ac3377633149401296f6c0d92d79dc16                                |
+------------+-----------------------------------------------------------------+
```

成功！

---

3. As the `myuser` user created in the previous, request an authentication token:

```
$ openstack --os-auth-url http://controller:5000/v3 \
  --os-project-domain-name Default --os-user-domain-name Default \
  --os-project-name myproject --os-username myuser token issue

Password:
+------------+-----------------------------------------------------------------+
| Field      | Value                                                           |
+------------+-----------------------------------------------------------------+
| expires    | 2016-02-12T20:15:39.014479Z                                     |
| id         | gAAAAABWvi9bsh7vkiby5BpCCnc-JkbGhm9wH3fabS_cY7uabOubesi-Me6IGWW |
|            | yQqNegDDZ5jw7grI26vvgy1J5nCVwZ_zFRqPiz_qhbq29mgbQLglbkq6FQvzBRQ |
|            | JcOzq3uwhzNxszJWmzGC7rJE_H0A_a3UFhqv8M4zMRYSbS2YF0MyFmp_U       |
| project_id | ed0b60bf607743088218b0a533d5943f                                |
| user_id    | 58126687cbcc4888bfa9ab73a2256f27                                |
+------------+-----------------------------------------------------------------+
```

##### 创建 OpenStack 客户端 环境脚本

###### 创建脚本

1. Create and edit the `admin-openrc` file and add the following content:

> Note
>
> The OpenStack client also supports using a `clouds.yaml` file. For more information, see the [os-client-config](http://docs.openstack.org/os-client-config/latest).

```
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=ADMIN_PASS
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
```

Replace `ADMIN_PASS` with the password you chose for the `admin` user in the Identity service.

2. Create and edit the `demo-openrc` file and add the following content:

```
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=myproject
export OS_USERNAME=myuser
export OS_PASSWORD=MYUSER_PASS
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
```

Replace `DEMO_PASS` with the password you chose for the `demo` user in the Identity service.

###### 使用脚本

1. Load the `admin-openrc` file to populate environment variables with the location of the Identity service and the `admin` project and user credentials:

   ```
   $ . admin-openrc
   ```

2. Request an authentication token:

   ```
   $ openstack token issue
   
   +------------+-----------------------------------------------------------------+
   | Field      | Value                                                           |
   +------------+-----------------------------------------------------------------+
   | expires    | 2016-02-12T20:44:35.659723Z                                     |
   | id         | gAAAAABWvjYj-Zjfg8WXFaQnUd1DMYTBVrKw4h3fIagi5NoEmh21U72SrRv2trl |
   |            | JWFYhLi2_uPR31Igf6A8mH2Rw9kv_bxNo1jbLNPLGzW_u5FC7InFqx0yYtTwa1e |
   |            | eq2b0f6-18KZyQhs7F3teAta143kJEWuNEYET-y7u29y0be1_64KYkM7E       |
   | project_id | 343d245e850143a096806dfaefa9afdc                                |
   | user_id    | ac3377633149401296f6c0d92d79dc16                                |
   +------------+-----------------------------------------------------------------+
   ```

---

### Glance 

> 在 controller node 上进行

#### 准备

1. To create the database, complete these steps:

- Use the database access client to connect to the database server as the `root` user:

  ```
  $ mysql -u root -p
  ```

- Create the `glance` database:

  ```
  MariaDB [(none)]> CREATE DATABASE glance;
  ```

- Grant proper access to the `glance` database:

  ```
  MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \
    IDENTIFIED BY 'GLANCE_DBPASS';
  MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \
    IDENTIFIED BY 'GLANCE_DBPASS';
  MariaDB [(none)]> flush privileges;
  ```

  Replace `GLANCE_DBPASS` with a suitable password.

- Exit the database access client.

2. Source the `admin` credentials to gain access to admin-only CLI commands:

```
$ . admin-openrc
```

3. To create the service credentials, complete these steps:

- Create the `glance` user:

  ```
  $ openstack user create --domain default --password-prompt glance
  
  User Password: GLANCE_PASS
  Repeat User Password: GLANCE_PASS
  +---------------------+----------------------------------+
  | Field               | Value                            |
  +---------------------+----------------------------------+
  | domain_id           | default                          |
  | enabled             | True                             |
  | id                  | 3f4e777c4062483ab8d9edd7dff829df |
  | name                | glance                           |
  | options             | {}                               |
  | password_expires_at | None                             |
  +---------------------+----------------------------------+
  ```

- Add the `admin` role to the `glance` user and `service` project:

  ```
  $ openstack role add --project service --user glance admin
  ```

- Create the `glance` service entity:

```
$ openstack service create --name glance \
  --description "OpenStack Image" image

+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Image                  |
| enabled     | True                             |
| id          | 8c2c7f1b9b5049ea9e63757b5533e6d2 |
| name        | glance                           |
| type        | image                            |
+-------------+----------------------------------+
```

4. Create the Image service API endpoints:

```
$ openstack endpoint create --region RegionOne \
  image public http://controller:9292

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 340be3625e9b4239a6415d034e98aace |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+

$ openstack endpoint create --region RegionOne \
  image internal http://controller:9292

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | a6e4b153c2ae4c919eccfdbb7dceb5d2 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+

$ openstack endpoint create --region RegionOne \
  image admin http://controller:9292

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 0c37ed58103f4300a84ff125a539032d |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
```

#### 安装配置

1. Install the packages:

```
# apt install glance
```

1. Edit the `/etc/glance/glance-api.conf` file and complete the following actions:

   - In the `[database]` section, configure database access:

     ```
     # 1883行
     [database]
     # ...
     connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance
     ```

     Replace `GLANCE_DBPASS` with the password you chose for the Image service database.

   - In the `[keystone_authtoken]` and `[paste_deploy]` sections, configure Identity service access:

     ```
     [keystone_authtoken]
     # ...
     # 3474行
     www_authenticate_uri = http://controller:5000
     auth_url = http://controller:5000
     memcached_servers = controller:11211
     auth_type = password
     project_domain_name = Default
     user_domain_name = Default
     project_name = service
     username = glance
     password = GLANCE_PASS
     
     [paste_deploy]
     # ...
     # 4426行
     flavor = keystone
     ```

     Replace `GLANCE_PASS` with the password you chose for the `glance` user in the Identity service.

     > Note
     >
     > Comment out or remove any other options in the `[keystone_authtoken]` section.

   - In the `[glance_store]` section, configure the local file system store and location of image files:

     ```
     [glance_store]
     # ...
     stores = file,http
     default_store = file
     filesystem_store_datadir = /var/lib/glance/images/
     ```

2. Edit the `/etc/glance/glance-registry.conf` file and complete the following actions:

   > Note
   >
   > The Glance Registry Service and its APIs have been DEPRECATED in the Queens release and are subject to removal at the beginning of the ‘S’ development cycle, following the [OpenStack standard deprecation policy](https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html).
   >
   > For more information, see the Glance specification document [Actually Deprecate the Glance Registry](http://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html).

   - In the `[database]` section, configure database access:

     ```
     [database]
     # ...
     # 1129行
     connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance
     ```

     Replace `GLANCE_DBPASS` with the password you chose for the Image service database.

   - In the `[keystone_authtoken]` and `[paste_deploy]` sections, configure Identity service access:

     ```
     [keystone_authtoken]
     # ...
     # 1260行
     www_authenticate_uri = http://controller:5000
     auth_url = http://controller:5000
     memcached_servers = controller:11211
     auth_type = password
     project_domain_name = Default
     user_domain_name = Default
     project_name = service
     username = glance
     password = GLANCE_PASS
     
     [paste_deploy]
     # ...
     # 2180行
     flavor = keystone
     ```

     Replace `GLANCE_PASS` with the password you chose for the `glance` user in the Identity service.

     

     > Note
     >
     > Comment out or remove any other options in the `[keystone_authtoken]` section.

3. Populate the Image service database:

   ```
   # su -s /bin/sh -c "glance-manage db_sync" glance
   ```

   > Note
   >
   > Ignore any deprecation messages in this output.

#### 完成安装

Restart the Image services:

```
# service glance-registry restart
# service glance-api restart

systemctl enable glance-registry glance-api
```

#### 验证

Verify operation of the Image service using [CirrOS](http://launchpad.net/cirros), a small Linux image that helps you test your OpenStack deployment.

1. Source the `admin` credentials to gain access to admin-only CLI commands:

   ```
   $ . admin-openrc
   ```

2. Download the source image:

   ```
   $ wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img
   ```

   > Note
   >
   > Install `wget` if your distribution does not include it.

   

3. Upload the image to the Image service using the [QCOW2](https://docs.openstack.org/glance/rocky/glossary.html#term-qemu-copy-on-write-2-qcow2) disk format, [bare](https://docs.openstack.org/glance/rocky/glossary.html#term-bare) container format, and public visibility so all projects can access it:

   ```
   $ openstack image create "cirros" \
     --file cirros-0.4.0-x86_64-disk.img \
     --disk-format qcow2 --container-format bare \
     --public
   
   +------------------+------------------------------------------------------+
   | Field            | Value                                                |
   +------------------+------------------------------------------------------+
   | checksum         | 133eae9fb1c98f45894a4e60d8736619                     |
   | container_format | bare                                                 |
   | created_at       | 2015-03-26T16:52:10Z                                 |
   | disk_format      | qcow2                                                |
   | file             | /v2/images/cc5c6982-4910-471e-b864-1098015901b5/file |
   | id               | cc5c6982-4910-471e-b864-1098015901b5                 |
   | min_disk         | 0                                                    |
   | min_ram          | 0                                                    |
   | name             | cirros                                               |
   | owner            | ae7a98326b9c455588edd2656d723b9d                     |
   | protected        | False                                                |
   | schema           | /v2/schemas/image                                    |
   | size             | 13200896                                             |
   | status           | active                                               |
   | tags             |                                                      |
   | updated_at       | 2015-03-26T16:52:10Z                                 |
   | virtual_size     | None                                                 |
   | visibility       | public                                               |
   +------------------+------------------------------------------------------+
   ```

   For information about the **openstack image create** parameters, see [Create or update an image (glance)](https://docs.openstack.org/user-guide/common/cli-manage-images.html#create-or-update-an-image-glance) in the `OpenStack User Guide`.

   For information about disk and container formats for images, see [Disk and container formats for images](https://docs.openstack.org/image-guide/image-formats.html) in the `OpenStack Virtual Machine Image Guide`.

   > Note
   >
   > OpenStack generates IDs dynamically, so you will see different values in the example command output.

   

4. Confirm upload of the image and validate attributes:

   ```
   $ openstack image list
   
   +--------------------------------------+--------+--------+
   | ID                                   | Name   | Status |
   +--------------------------------------+--------+--------+
   | 38047887-61a7-41ea-9b49-27987d5e8bb9 | cirros | active |
   +--------------------------------------+--------+--------+
   ```

----

> controller node 创建快照
>
> glance

---

### nova 

#### 准备

systemctl enable nova-compute





---

### neutron

#### 准备

##### 控制节点安装配置

> 控制节点进行

###### 为neutron添加数据库

- Use the database access client to connect to the database server as the `root` user:

  ```
  # mysql
  ```

- Create the `neutron` database:

  ```
  MariaDB [(none)] CREATE DATABASE neutron;
  ```

- Grant proper access to the `neutron` database, replacing `NEUTRON_DBPASS` with a suitable password:

  ```
  MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \
    IDENTIFIED BY 'NEUTRON_DBPASS';
  MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \
    IDENTIFIED BY 'NEUTRON_DBPASS';
  MariaDB [(none)]> flush privileges;
  ```

- Exit the database access client.

~~~
exit
~~~

###### 在Keystone中添加用户及其他服务相关

1. Source the `admin` credentials to gain access to admin-only CLI commands:

   ```
   $ . admin-openrc
   ```

2. To create the service credentials, complete these steps:

   - Create the `neutron` user:

     ```
     $ openstack user create --domain default --project service --password-prompt neutron
     
     User Password: NEUTRON_PASS
     Repeat User Password:
     +---------------------+----------------------------------+
     | Field               | Value                            |
     +---------------------+----------------------------------+
     | default_project_id  | cc60f7c2d98347e0832bfa02b21ae94f |
     | domain_id           | default                          |
     | enabled             | True                             |
     | id                  | a42c98d6a0a741a98ca664c6c40e391a |
     | name                | neutron                          |
     | options             | {}                               |
     | password_expires_at | None                             |
     +---------------------+----------------------------------+
     ```

   - Add the `admin` role to the `neutron` user:

     ```
     $ openstack role add --project service --user neutron admin
     ```

   - Create the `neutron` service entity:

     ```
     $ openstack service create --name neutron \
       --description "OpenStack Networking" network
     
     +-------------+----------------------------------+
     | Field       | Value                            |
     +-------------+----------------------------------+
     | description | OpenStack Networking             |
     | enabled     | True                             |
     | id          | f71529314dab4a4d8eca427e701d209e |
     | name        | neutron                          |
     | type        | network                          |
     +-------------+----------------------------------+
     ```

4. Create the Networking service API endpoints:

```
$ openstack endpoint create --region RegionOne \
  network public http://controller:9696

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 85d80a6d02fc4b7683f611d7fc1493a3 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | f71529314dab4a4d8eca427e701d209e |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+

$ openstack endpoint create --region RegionOne \
  network internal http://controller:9696

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 09753b537ac74422a68d2d791cf3714f |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | f71529314dab4a4d8eca427e701d209e |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+

$ openstack endpoint create --region RegionOne \
  network admin http://controller:9696

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 1ee14289c9374dffb5db92a5c112fc4e |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | f71529314dab4a4d8eca427e701d209e |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
```

##### 

---

###### 开始安装

~~~
# 安装
apt -y install neutron-server neutron-metadata-agent neutron-plugin-ml2 python-neutronclient
~~~

###### 配置neutron

- Edit the `/etc/neutron/neutron.conf` file and complete the following actions:

  ~~~
  vim /etc/neutron/neutron.conf
  ~~~

  

  - In the `[database]` section, configure database access:

    ```
    [database]
    # ...
    connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron
    ```

    Replace `NEUTRON_DBPASS` with the password you chose for the database.

    

    > Note
    >
    > Comment out or remove any other `connection` options in the `[database]` section.

  

  - In the `[DEFAULT]` section, enable the Modular Layer 2 (ML2) plug-in and disable additional plug-ins:

    ```
    [DEFAULT]
    # ...
    core_plugin = ml2
    service_plugins = router
    allow_overlapping_ips = true
    ```

  - In the `[DEFAULT]` section, configure `RabbitMQ` message queue access:

    ```
    [DEFAULT]
    # ...
    transport_url = rabbit://openstack:RABBIT_PASS@controller
    ```

    Replace `RABBIT_PASS` with the password you chose for the `openstack` account in RabbitMQ.

  - In the `[DEFAULT]` and `[keystone_authtoken]` sections, configure Identity service access:

    ```
    [DEFAULT]
    # ...
    auth_strategy = keystone
    state_path = /var/lib/neutron
    
    [keystone_authtoken]
    # ...
    www_authenticate_uri = http://controller:5000
    auth_url = http://controller:5000
    memcached_servers = controller:11211
    auth_type = password
    project_domain_name = default
    user_domain_name = default
    project_name = service
    username = neutron
    password = NEUTRON_PASS
    ```

    Replace `NEUTRON_PASS` with the password you chose for the `neutron` user in the Identity service.

     

    > Note
    >
    > Comment out or remove any other options in the `[keystone_authtoken]` section.

    

  - In the `[DEFAULT]` and `[nova]` sections, configure Networking to notify Compute of network topology changes:

    ```
    [DEFAULT]
    # ...
    notify_nova_on_port_status_changes = true
    notify_nova_on_port_data_changes = true
    
    [nova]
    # ...
    [nova]
    # ...
    auth_url = http://controller:5000
    auth_type = password
    project_domain_name = default
    user_domain_name = default
    region_name = RegionOne
    project_name = service
    username = nova
    password = NOVA_PASS
    ```

    Replace `NOVA_PASS` with the password you chose for the `nova` user in the Identity service.

- In the `[oslo_concurrency]` section, configure the lock path:

  ```
  [oslo_concurrency]
  # ...
  lock_path = /var/lib/neutron/tmp
  ```

----

###### 配置 Modular Layer 2 (ML2) plug-in

Edit the `/etc/neutron/plugins/ml2/ml2_conf.ini` file and complete the following actions:

- In the `[ml2]` section, enable flat, VLAN, and VXLAN networks:

  ```
  [ml2]
  # ...
  type_drivers = flat,vlan,vxlan
  ```

- In the `[ml2]` section, enable VXLAN self-service networks:

  ```
  [ml2]
  # ...
  tenant_network_types = vxlan
  ```

- In the `[ml2]` section, enable the Linux bridge and layer-2 population mechanisms:

  ```
  [ml2]
  # ...
  mechanism_drivers = linuxbridge,l2population
  ```

   

  > Warning
  >
  > After you configure the ML2 plug-in, removing values in the `type_drivers` option can lead to database inconsistency.

  > 
  >
  > Note
  >
  > The Linux bridge agent only supports VXLAN overlay networks.

  

- In the `[ml2]` section, enable the port security extension driver:

  ```
  [ml2]
  # ...
  extension_drivers = port_security
  ```

- In the `[ml2_type_flat]` section, configure the provider virtual network as a flat network:

  ```
  [ml2_type_flat]
  # ...
  # flat_networks = provider
  ```

- In the `[ml2_type_vxlan]` section, configure the VXLAN network identifier range for self-service networks:

  ```
  [ml2_type_vxlan]
  # ...
  vni_ranges = 1:1000
  ```

- In the `[securitygroup]` section, enable ipset to increase efficiency of security group rules:

  ```
  [securitygroup]
  # ...
  enable_ipset = true
  ```

  ~~~
  enable_security_group = True
  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
  ~~~

###### 配置metadata agent

Edit the `/etc/neutron/metadata_agent.ini` file and complete the following actions:

- In the `[DEFAULT]` section, configure the metadata host and shared secret:

  ```
  [DEFAULT]
  # ...
  nova_metadata_host = controller
  metadata_proxy_shared_secret = METADATA_SECRET
  memcache_servers = 192.168.1.10:11211
  ```

  

###### 配置 nova

Edit the `/etc/nova/nova.conf` file and perform the following actions:

- [default] section, configure for LinuxBriage

  ~~~
  [default] 
  use_neutron = True
  firewall_driver = nova.virt.firewall.NoopFirewallDriver
  linuxnet_interface_driver = nova.network.linux_net.LinuxBridgeInterfaceDriver
  ~~~

  

- In the `[neutron]` section, configure access parameters, enable the metadata proxy, and configure the secret:

  ```
  [neutron]
  # ...
  url = http://controller:9696
  auth_url = http://controller:5000
  auth_type = password
  project_domain_name = default
  user_domain_name = default
  region_name = RegionOne
  project_name = service
  username = neutron
  password = NEUTRON_PASS
  service_metadata_proxy = true
  metadata_proxy_shared_secret = METADATA_SECRET
  ```

###### 创建连接文件、同步数据库、重启服务

~~~
# 创建连接文件
ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
 
# 同步数据库
su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf \
  --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron
 
# 重启相关服务并设置自启动
systemctl restart neutron-server neutron-metadata-agent nova-api
systemctl enable neutron-server neutron-metadata-agent
~~~

##### 计算节点安装配置

> 在计算机节点进行

###### 开始安装

```
apt -y install neutron-common neutron-linuxbridge-agent neutron-plugin-ml2
```

###### 配置 neutron

- Edit the `/etc/neutron/neutron.conf` file and complete the following actions:

  - In the `[database]` section, comment out any `connection` options because compute nodes do not directly access the database.

  - In the `[DEFAULT]` section, configure `RabbitMQ` message queue access:

    ```
    [DEFAULT]
    
    service_plugins = router
    state_path = /var/lib/neutron
    allow_overlapping_ips = True
    # ...
    transport_url = rabbit://openstack:RABBIT_PASS@controller
    ```

    Replace `RABBIT_PASS` with the password you chose for the `openstack` account in RabbitMQ.

  - In the `[DEFAULT]` and `[keystone_authtoken]` sections, configure Identity service access:

    ```
    [DEFAULT]
    # ...
    auth_strategy = keystone
    
    [keystone_authtoken]
    # ...
    www_authenticate_uri = http://controller:5000
    auth_url = http://controller:5000
    memcached_servers = controller:11211
    auth_type = password
    project_domain_name = default
    user_domain_name = default
    project_name = service
    username = neutron
    password = NEUTRON_PASS
    
    ```

    Replace `NEUTRON_PASS` with the password you chose for the `neutron` user in the Identity service.

     

    > Note
    >
    > Comment out or remove any other options in the `[keystone_authtoken]` section.

    

- In the `[oslo_concurrency]` section, configure the lock path:

  ```
  [oslo_concurrency]
  # ...
  lock_path = /var/lib/neutron/tmp
  ```

###### 配置 Modular Layer 2 (ML2) plug-in

~~~
[ml2]
type_drivers = flat,vlan,vxlan
tenant_network_types =
mechanism_drivers = linuxbridge,l2population
extension_drivers = port_security

enable_security_group = True
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver

enable_ipset = True
~~~

###### 配置 Linux bridge agent

Edit the `/etc/neutron/plugins/ml2/linuxbridge_agent.ini` file and complete the following actions:

- In the `[linux_bridge]` section, map the provider virtual network to the provider physical network interface:

  ```
  [linux_bridge]
  physical_interface_mappings = provider:ens224
  ```

  

- In the `[vxlan]` section, enable VXLAN overlay networks, configure the IP address of the physical network interface that handles overlay networks, and enable layer-2 population:

  ```
  [vxlan]
  enable_vxlan = true
  local_ip = 192.168.2.20
  l2_population = true
  ```

  

- In the `[securitygroup]` section, enable security groups and configure the Linux bridge iptables firewall driver:

  ```
  [securitygroup]
  # ...
  enable_security_group = true
  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
  ```

- Ensure your Linux operating system kernel supports network bridge filters by verifying all the following `sysctl` values are set to `1`:

  ```
  net.bridge.bridge-nf-call-iptables
  net.bridge.bridge-nf-call-ip6tables
  ```

  To enable networking bridge support, typically the `br_netfilter` kernel module needs to be loaded. Check your operating system’s documentation for additional details on enabling this module.

###### 配置 nova

Edit the `/etc/nova/nova.conf` file and complete the following actions:

- In the `[neutron]` section, configure access parameters:

  ```
  [DEFAULT]
  use_neutron = True
  linuxnet_interface_driver = nova.network.linux_net.LinuxBridgeInterfaceDriver
  firewall_driver = nova.virt.firewall.NoopFirewallDriver
  vif_plugging_is_fatal = True
  vif_plugging_timeout = 300
  
  [neutron]
  # ...
  url = http://controller:9696
  auth_url = http://controller:5000
  auth_type = password
  project_domain_name = default
  user_domain_name = default
  region_name = RegionOne
  project_name = service
  username = neutron
  password = NEUTRON_PASS
  
  service_metadata_proxy = True
  metadata_proxy_shared_secret = metadata_secret
  
  ```

  ###### 创建连接文件、重启服务

~~~
# 创建连接文件
ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
 
# 重启服务
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
systemctl enable neutron-linuxbridge-agent
systemctl restart nova-compute neutron-linuxbridge-agent

~~~



###### 参考资料

https://blog.csdn.net/tycoon1988/article/details/40826235

~~~
cat >> /etc/sysctl.conf <<EOF

  net.bridge.bridge-nf-call-ip6tables = 0
  net.bridge.bridge-nf-call-iptables = 0
  net.bridge.bridge-nf-call-arptables = 0
  EOF

sysctl -p /etc/sysctl.conf

或者改用下面的方法解决：

 iptables -t raw -I PREROUTING -i BRIDGE -s x.x.x.x -j NOTRACK.

如果net.bridge.bridge-nf-call-iptables＝1，也就意味着二层的网桥在转发包时也会被iptables的FORWARD规则所过滤，这样就会出现L3层的iptables rules去过滤L2的帧的问题


# -----------------------------------------------------
vim /etc/sysctl.conf

net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1

sysctl -p /etc/sysctl.conf
~~~



##### 网络节点安装配置

> 在网络节点进行

###### 安装配置

~~~
apt -y install  neutron-plugin-ml2 neutron-linuxbridge-agent neutron-l3-agent neutron-dhcp-agent  neutron-metadata-agent
~~~

###### 配置neutron

Edit the `/etc/neutron/neutron.conf` file and complete the following actions:

~~~
# 注释掉 [database] 内的 connection

[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
state_path = /var/lib/neutron
allow_overlapping_ips = True
# 消息队列连接设置
transport_url = rabbit://openstack:RABBIT_PASS@controller

# Keystone连接设置
[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = NEUTRON_PASS

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp
~~~

###### 配置 l3_agent

~~~
vim /etc/neutron/l3_agent.ini

# 第17行：去掉注释并添加
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
interface_driver = linuxbridge
 
⚠ 如果使用OVS作为虚拟交换机则为以下代码
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
 
~~~

###### 配置DHCP_agent

~~~
vim /etc/neutron/dhcp_agent.ini

# 官网
[DEFAULT]
# ...
interface_driver = linuxbridge
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = true

# -----------------------------------------------------------------
# 第17行：去掉注释并添加
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
interface_driver = neutron.agent.linux.interface.BridgeInterfaceDriver
 
⚠ 如果使用OVS作为虚拟交换机则为以下代码
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
 
# 第28行：去掉注释
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
 
# 第37行：取消注释并修改
enable_isolated_metadata = True
~~~

###### 配置 metadata_agent

~~~

# 修改元数据代理配置
vim /etc/neutron/metadata_agent.ini

# 官网
[DEFAULT]
# ...
nova_metadata_host = controller
metadata_proxy_shared_secret = METADATA_SECRET

# ---------------------------------------------------------
 
# 第17行：去掉注释并添加控制节点IP
nova_metadata_host = 192.168.0.10
 
# 第34行：去掉注释并添加元数据代理共享密码
metadata_proxy_shared_secret = metadata_secret
 
# 第260行：去掉注释并添加控制节点IP
memcache_servers = 192.168.0.10:11211
~~~

###### 配置 ml2

~~~
vim /etc/neutron/plugins/ml2/ml2_conf.ini

# 官网
[ml2]
# ...
type_drivers = flat,vlan,vxlan

tenant_network_types = vxlan

mechanism_drivers = linuxbridge,l2population

extension_drivers = port_security

[ml2_type_flat]
# ...
flat_networks = provider

[ml2_type_vxlan]
# ...
vni_ranges = 1:1000

[securitygroup]
# ...
enable_ipset = true
 
# ---------------------------------------------------------------------
# 第129行：添加相应设置（tenant_network_types设置暂时留空，之后会设置）
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
[ml2]
type_drivers = flat,vlan,vxlan
tenant_network_types =
mechanism_drivers = linuxbridge,l2population
extension_drivers = port_security
 
⚠ 如果使用OVS作为虚拟交换机则为以下代码
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types =
mechanism_drivers = openvswitch,l2population
extension_drivers = port_security
 
# 第262行：去掉注释并添加firewall_driver
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
enable_security_group = True
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
 
⚠ 如果使用OVS作为虚拟交换机则为以下代码
enable_security_group = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
 
# 最后一行：取消注释
enable_ipset = True
~~~

###### 配置Linuxbridge_agent

~~~
vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini

# 官网
[linux_bridge]
physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME
# PROVIDER_INTERFACE_NAME = ens224
[vxlan]
enable_vxlan = true
local_ip = OVERLAY_INTERFACE_IP_ADDRESS
l2_population = true
# OVERLAY_INTERFACE_IP_ADDRESS = 192.168.2.30
[securitygroup]
# ...
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver

# ------------------------------------------------------------------
# 第235行：取消注释并添加本节点的数据网络IP
local_ip = 192.168.2.30
~~~

###### 创建连接文件、重启服务

~~~
# 创建连接文件
ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
 
# 重启服务
⚠ 如果使用LinuxBridge作为虚拟交换机则为以下代码
systemctl enable neutron-linuxbridge-agent neutron-l3-agent neutron-dhcp-agent neutron-metadata-agent
systemctl restart neutron-linuxbridge-agent neutron-l3-agent neutron-dhcp-agent neutron-metadata-agent
~~~

#### 验证

http://www.veryveryopen.cn/Documents/document_014.html

> 在控制节点进行

~~~
# 查看列表
. admin-openrc
openstack network agent list

# 查看log
 cat /var/log/neutron/neutron-linuxbridge-agent.log
 						neutron-server.log
 						neutron-dhcp-agent.log
 						neutron-metadata-agent.log
 						neutron-l3-agent.log
 						neutron-linuxbridge-cleanup.log
 						neutron-server.log
 		
~~~

------

一. 配置控制节点

~~~
root@controller:~(keystone)# vim /etc/neutron/plugins/ml2/ml2_conf.ini

\# 第130行：添加网络类型
tenant_network_types = vxlan
 

\# 第181行：添加
flat_networks = physnet1

\# 第235行：添加
vni_ranges = 1:1000

root@controller:~(keystone)# systemctl restart neutron-server


~~~



二. 配置网络节点

~~~
root@network:~# vim /etc/neutron/plugins/ml2/ml2_conf.ini

\# 第130行：添加网络类型
tenant_network_types = vxlan

\# 第181行：添加
flat_networks = physnet1
 
\# 第235行：添加
vni_ranges = 1:1000

root@network:~# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini

\# 第118行：添加
[agent]
prevent_arp_spoofing = True

\# 第147行：添加
[linux_bridge]
physical_interface_mappings = physnet1:ens3

\# 第201行：添加
[vxlan]
enable_vxlan = True
l2_population = True

root@network:~# vim /etc/neutron/dhcp_agent.ini

\# 第63行：添加
dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf

root@network:~# vim /etc/neutron/dnsmasq-neutron.conf

\# 这是一个新文件，添加以下内容
dhcp-option-force=26,1450

root@network:~# for service in l3-agent dhcp-agent metadata-agent linuxbridge-agent; do
systemctl restart neutron-$service
done
~~~



三. 配置计算节点

~~~
root@compute:~# vim /etc/neutron/plugins/ml2/ml2_conf.ini


\# 第130行：添加网络类型
tenant_network_types = vxlan

\# 第181行：添加
flat_networks = physnet1

\# 第235行：添加
vni_ranges = 1:1000

root@compute:~# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini


\# 第118行：添加
[agent]
prevent_arp_spoofing = True
 

\# 第201行：添加
[vxlan]
enable_vxlan = True
l2_population = True

 
root@compute# systemctl restart neutron-linuxbridge-agent
~~~



四. 创建网络及路由（控制节点上完成）

[1] 创建虚拟路由

~~~
root@controller:~(keystone)# openstack router create router_01
~~~

```
+-------------------------+--------------------------------------+
| Field                   | Value                                |
+-------------------------+--------------------------------------+
| admin_state_up          | UP                                   |
| availability_zone_hints |                                      |
| availability_zones      |                                      |
| created_at              | 2018-07-01T09:23:14Z                 |
| description             |                                      |
| distributed             | False                                |
| external_gateway_info   | None                                 |
| flavor_id               | None                                 |
| ha                      | False                                |
| id                      | c3ls8351-1952-3s85-2f95-02335s8j30s1 |
| name                    | router_01                            |
| project_id              | 29j348sj583h6i1j238zk20so1jf91j2     |
| revision_number         | 0                                    |
| routes                  |                                      |
| status                  | ACTIVE                               |
| tags                    |                                      |
| updated_at              | 2018-07-01T09:23:14Z                 |
+-------------------------+--------------------------------------+
```



[2] 创建外部网络

~~~
root@controller:~(keystone)# openstack network create \
--provider-physical-network physnet1 \
--provider-network-type flat --external ext_net
~~~



```
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | UP                                   |
| availability_zone_hints   |                                      |
| availability_zones        |                                      |
| created_at                | 2018-07-01T09:24:12Z                 |
| description               |                                      |
| dns_domain                | None                                 |
| id                        | 25j29sj3-sd21-9s1a-1d02-2296038k28sj |
| ipv4_address_scope        | None                                 |
| ipv6_address_scope        | None                                 |
| is_default                | False                                |
| is_vlan_transparent       | None                                 |
| mtu                       | 1500                                 |
| name                      | ext_net                              |
| port_security_enabled     | True                                 |
| project_id                | 29j348sj583h6i1j238zk20so1jf91j2     |
| provider:network_type     | flat                                 |
| provider:physical_network | physnet1                             |
| provider:segmentation_id  | None                                 |
| qos_policy_id             | None                                 |
| revision_number           | 5                                    |
| router:external           | External                             |
| segments                  | None                                 |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tags                      |                                      |
| updated_at                | 2018-07-01T09:24:12Z                 |
+---------------------------+--------------------------------------+
```

 

\# 创建外部网络的子网

~~~
root@controller:~(keystone)# openstack subnet create subnet_01 \
--network ext_net --subnet-range 10.0.0.0/24 \
--allocation-pool start=10.0.0.50,end=10.0.0.100 \
--gateway 10.0.0.1 --dns-nameserver 10.0.0.1 --no-dhcp
~~~



```
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| allocation_pools  | 10.0.0.50-10.0.0.100                 |
| cidr              | 10.0.0.0/24                          |
| created_at        | 2018-07-01T09:24:49Z                 |
| description       |                                      |
| dns_nameservers   | 10.0.0.1                             |
| enable_dhcp       | False                                |
| gateway_ip        | 10.0.0.1                             |
| host_routes       |                                      |
| id                | 239n75s8-2bx8-1953-1k9s-3js9gz55q934 |
| ip_version        | 4                                    |
| ipv6_address_mode | None                                 |
| ipv6_ra_mode      | None                                 |
| name              | subnet2                              |
| network_id        | 25j29sj3-sd21-9s1a-1d02-2296038k28sj |
| project_id        | 29j348sj583h6i1j238zk20so1jf91j2     |
| revision_number   | 0                                    |
| segment_id        | None                                 |
| service_types     |                                      |
| subnetpool_id     | None                                 |
| tags              |                                      |
| updated_at        | 2018-07-01T09:24:49Z                 |
+-------------------+--------------------------------------+
```

 

\# 连接外部网络到路由

~~~
root@controller:~(keystone)# openstack router set router_01 --external-gateway ext_net
~~~

[3] 创建内部网络

~~~
root@controller:~(keystone)# openstack network create int_net --provider-network-type vxlan
~~~



```
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | UP                                   |
| availability_zone_hints   |                                      |
| availability_zones        |                                      |
| created_at                | 2018-07-01T09:24:58Z                 |
| description               |                                      |
| dns_domain                | None                                 |
| id                        | 3396hn93-ak63-jj92-1l30-2394jsu2o49s |
| ipv4_address_scope        | None                                 |
| ipv6_address_scope        | None                                 |
| is_default                | False                                |
| is_vlan_transparent       | None                                 |
| mtu                       | 1450                                 |
| name                      | int_net                              |
| port_security_enabled     | True                                 |
| project_id                | 29j348sj583h6i1j238zk20so1jf91j2     |
| provider:network_type     | vxlan                                |
| provider:physical_network | None                                 |
| provider:segmentation_id  | 60                                   |
| qos_policy_id             | None                                 |
| revision_number           | 2                                    |
| router:external           | Internal                             |
| segments                  | None                                 |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tags                      |                                      |
| updated_at                | 2018-07-01T09:24:58Z                 |
+---------------------------+--------------------------------------+
```

 

\# 创建内部网络的子网

~~~
root@controller:~(keystone)# openstack subnet create subnet_02 --network int_net \
--subnet-range 192.168.100.0/24 --gateway 192.168.100.1 \
--dns-nameserver 10.0.0.1
~~~



\# 连接内部网络到路由

~~~
root@controller:~(keystone)# openstack router add subnet router_01 subnet_02
~~~

### Horizon



#### 问题汇总

1. 添加实例遇到错误  提示nova-api，查看controller node  /var/log/nova/nova-api.log：

~~~
Unable to connect to AMQP server on controller:5672
... Login was refused using authentication mechanism AMQPLAIN...

rabbitmq 服务也启动了
最后发现创建的 ‘openstack’用户不见了
// 查看当前rabbitmq的用户
rabbitmqctl list_users
执行创建用户，即可

~~~































